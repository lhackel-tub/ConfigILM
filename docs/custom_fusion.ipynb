{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Customize Fusion Approach\n",
    "\n",
    "`ConfigILM` supports a variety of fusion approaches. In this notebook, we will demonstrate how to customize the fusion approach by implementing a custom fusion approach and how to use it with `ConfigILM` as well as how to use the fusion approaches provided by `ConfigILM`.\n",
    "\n",
    "## Fusion Approaches provided by ConfigILM\n",
    "\n",
    "`ConfigILM` provides a wide range of fusion approaches. Details of the fusion approaches provided by `ConfigILM` can be found [here](https://lhackel-tub.github.io/ConfigILM/API/api_fusion.html). All methods are implemented as `nn.Module` with a harmonized interface. Depending on the fusion approach, the input to the fusion module can be a list of tensors or a single tensor. The output of the fusion module is a single tensor. An example of a fusion module is shown below: "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3e7a0ffa49c5b585"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:05:15.158984Z",
     "start_time": "2024-06-12T10:05:14.143596Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from configilm.Fusion.TuckerFusion import Tucker\n",
    "\n",
    "fusion_dim = 30\n",
    "output_dim = 10\n",
    "\n",
    "fusion = Tucker(\n",
    "    input_dims=[fusion_dim, fusion_dim],\n",
    "    output_dim=output_dim,\n",
    "    mm_dim=25,\n",
    ")\n",
    "\n",
    "t1 = torch.randn(fusion_dim)\n",
    "t2 = torch.randn(fusion_dim)\n",
    "output = fusion(input_0=t1, input_1=t2)\n",
    "assert output.shape == (output_dim,)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "This fusion module takes two input tensors with dimensions 20 and 30, respectively, and produces a single output tensor with dimension 10. The `mm_dim` parameter specifies the dimension of the middle mode in the Tucker decomposition.\n",
    "\n",
    "This fusion can be used with `ConfigILM` as shown below:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9edb6aa7ada441c9"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonard/.cache/pypoetry/virtualenvs/configilm-l7TjLRMG-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/leonard/Documents/development/ConfigILM/configilm/ConfigILM.py:134: UserWarning: Keyword 'img_size' unknown. Trying to ignore and restart creation.\n",
      "  warnings.warn(f\"Keyword '{failed_kw}' unknown. Trying to ignore and restart creation.\")\n",
      "/home/leonard/Documents/development/ConfigILM/configilm/ConfigILM.py:108: UserWarning: Tokenizer was initialized pretrained\n",
      "  warnings.warn(\"Tokenizer was initialized pretrained\")\n"
     ]
    }
   ],
   "source": [
    "from configilm.ConfigILM import ConfigILM, ILMConfiguration, ILMType\n",
    "\n",
    "configurations = ILMConfiguration(\n",
    "    timm_model_name=\"resnet18\",\n",
    "    hf_model_name=\"prajjwal1/bert-tiny\",\n",
    "    fusion_in=fusion_dim,\n",
    "    fusion_out=output_dim,\n",
    "    custom_fusion_method=(\"Tucker\", fusion),\n",
    "    network_type=ILMType.VQA_CLASSIFICATION,\n",
    ")\n",
    "model = ConfigILM(configurations)\n",
    "\n",
    "v = torch.rand((3, 3, 224, 224))\n",
    "q = torch.randint(0, 1000, (3, 10), dtype=torch.long)\n",
    "output = model((v, q))\n",
    "assert output.shape == (3, 10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:05:16.550102Z",
     "start_time": "2024-06-12T10:05:15.160884Z"
    }
   },
   "id": "8c5d783d6ace1daf",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Fusion Approach\n",
    "\n",
    "To implement a custom fusion approach, you need to create a callable method, e.g. a subclass of `nn.Module`. The `forward` method should take the input tensors and return the output tensor. An example of a custom fusion module is shown below:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b50f0d763bb5f04b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class CustomFusion(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomFusion, self).__init__()\n",
    "        self.operation = torch.mul\n",
    "\n",
    "    def forward(self, input_0, input_1):\n",
    "        return self.operation(input_0, input_1)\n",
    "\n",
    "custom_fusion = CustomFusion()\n",
    "assert custom_fusion(torch.tensor(2), torch.tensor(3)) == 6"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:05:16.556403Z",
     "start_time": "2024-06-12T10:05:16.551378Z"
    }
   },
   "id": "6951860d81c287e6",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "This custom fusion module takes two input tensors and multiplies them element-wise. To use the custom fusion module with `ConfigILM`, you need to provide the custom fusion module as a tuple with the name of the custom fusion module and the fusion definition. The custom fusion module can be used with `ConfigILM` as shown below.\n",
    "\n",
    ":::{note}\n",
    "It is important that the name of the custom fusion module is exactly the same as when the custom fusion module is defined. This is needed for importing the custom fusion module.\n",
    ":::"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "34f47951e4535617"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "CustomFusion()"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurations = ILMConfiguration(\n",
    "    timm_model_name=\"resnet18\",\n",
    "    hf_model_name=\"prajjwal1/bert-tiny\",\n",
    "    fusion_in=fusion_dim,\n",
    "    fusion_out=fusion_dim,\n",
    "    custom_fusion_method=(\"CustomFusion\", custom_fusion),\n",
    "    network_type=ILMType.VQA_CLASSIFICATION,\n",
    ")\n",
    "model = ConfigILM(configurations)\n",
    "\n",
    "v = torch.rand((3, 3, 224, 224))\n",
    "q = torch.randint(0, 1000, (3, 10), dtype=torch.long)\n",
    "output = model((v, q))\n",
    "assert output.shape == (3, 10)\n",
    "\n",
    "model.config.fusion_method"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:05:16.740268Z",
     "start_time": "2024-06-12T10:05:16.558835Z"
    }
   },
   "id": "e565386ddba5055b",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NameError occurred\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/leonard/Documents/development/ConfigILM/configilm/ConfigILM.py:134: UserWarning: Keyword 'img_size' unknown. Trying to ignore and restart creation.\n",
      "  warnings.warn(f\"Keyword '{failed_kw}' unknown. Trying to ignore and restart creation.\")\n",
      "/home/leonard/Documents/development/ConfigILM/configilm/ConfigILM.py:108: UserWarning: Tokenizer was initialized pretrained\n",
      "  warnings.warn(\"Tokenizer was initialized pretrained\")\n"
     ]
    }
   ],
   "source": [
    "# using a different name won't work\n",
    "configurations = ILMConfiguration(\n",
    "    timm_model_name=\"resnet18\",\n",
    "    hf_model_name=\"prajjwal1/bert-tiny\",\n",
    "    fusion_in=fusion_dim,\n",
    "    fusion_out=fusion_dim,\n",
    "    custom_fusion_method=(\"DifferentName\", custom_fusion),\n",
    "    network_type=ILMType.VQA_CLASSIFICATION,\n",
    ")\n",
    "model = ConfigILM(configurations)\n",
    "\n",
    "v = torch.rand((3, 3, 224, 224))\n",
    "q = torch.randint(0, 1000, (3, 10), dtype=torch.long)\n",
    "try:\n",
    "    output = model((v, q))\n",
    "except NameError as e:\n",
    "    print(\"NameError occurred\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:06:13.887598Z",
     "start_time": "2024-06-12T10:06:13.690364Z"
    }
   },
   "id": "527bbcfd68cde6b6",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using a correct name for the custom fusion module is important. If the name is not correct, the wrong fusion module will be used. This may work but will not provide the expected results.\n",
    "\n",
    "In the result below, we can see that the `CustomFusion` module is used for fusion, even tho we expected DifferentCustomFusion to be used."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3d30bcc9b426723"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "CustomFusion()"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DifferentCustomFusion(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DifferentCustomFusion, self).__init__()\n",
    "        self.operation = torch.add\n",
    "\n",
    "    def forward(self, input_0, input_1):\n",
    "        return self.operation(input_0, input_1)\n",
    "    \n",
    "different_custom_fusion = DifferentCustomFusion()\n",
    "configurations = ILMConfiguration(\n",
    "    timm_model_name=\"resnet18\",\n",
    "    hf_model_name=\"prajjwal1/bert-tiny\",\n",
    "    fusion_in=fusion_dim,\n",
    "    fusion_out=fusion_dim,\n",
    "    custom_fusion_method=(\"CustomFusion\", different_custom_fusion),\n",
    "    network_type=ILMType.VQA_CLASSIFICATION,\n",
    ")\n",
    "\n",
    "model = ConfigILM(configurations)\n",
    "\n",
    "v = torch.rand((3, 3, 224, 224))\n",
    "q = torch.randint(0, 1000, (3, 10), dtype=torch.long)\n",
    "output = model((v, q))\n",
    "assert output.shape == (3, 10)\n",
    "\n",
    "model.config.fusion_method"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39725f2cb7b6f71",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "The customised fusion does not have to be a subclass, it can also be a function. The function should take the input tensors and return the output tensor. An example of a custom fusion function is shown below:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ee2d988b320d05f3"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<function __main__.custom_fusion_function(input_0, input_1)>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def custom_fusion_function(input_0, input_1):\n",
    "    return input_0 + input_1\n",
    "\n",
    "assert custom_fusion_function(torch.tensor(2), torch.tensor(3)) == 5\n",
    "\n",
    "configurations = ILMConfiguration(\n",
    "    timm_model_name=\"resnet18\",\n",
    "    hf_model_name=\"prajjwal1/bert-tiny\",\n",
    "    fusion_in=fusion_dim,\n",
    "    fusion_out=fusion_dim,\n",
    "    custom_fusion_method=(\"custom_fusion_function\", custom_fusion_function),\n",
    "    network_type=ILMType.VQA_CLASSIFICATION,\n",
    ")\n",
    "model = ConfigILM(configurations)\n",
    "\n",
    "v = torch.rand((3, 3, 224, 224))\n",
    "q = torch.randint(0, 1000, (3, 10), dtype=torch.long)\n",
    "output = model((v, q))\n",
    "assert output.shape == (3, 10)\n",
    "\n",
    "model.config.fusion_method"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:12:37.558102Z",
     "start_time": "2024-06-12T10:12:37.389391Z"
    }
   },
   "id": "4117ce8fde995869",
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "or it can be any number of already existing functions."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46ffd2ab3cae4656"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "<function torch._VariableFunctionsClass.mul>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configurations = ILMConfiguration(\n",
    "    timm_model_name=\"resnet18\",\n",
    "    hf_model_name=\"prajjwal1/bert-tiny\",\n",
    "    fusion_in=fusion_dim,\n",
    "    fusion_out=fusion_dim,\n",
    "    custom_fusion_method=(\"torch.mul\", torch.mul),\n",
    "    network_type=ILMType.VQA_CLASSIFICATION,\n",
    ")\n",
    "model = ConfigILM(configurations)\n",
    "\n",
    "v = torch.rand((3, 3, 224, 224))\n",
    "q = torch.randint(0, 1000, (3, 10), dtype=torch.long)\n",
    "output = model((v, q))\n",
    "assert output.shape == (3, 10)\n",
    "\n",
    "model.config.fusion_method"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-12T10:13:33.052692Z",
     "start_time": "2024-06-12T10:13:32.885777Z"
    }
   },
   "id": "6455168850516a3",
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
