{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Model Configuration\n",
    "\n",
    "The central object of `ConfigILM` is the dataclass `ILMConfiguration`. This is used to decide which parts the model consists of, how it is combined, and which task it should ultimately solve. A possible minimal configuration for Supervised Classification can look like this:\n",
    ":::{note}\n",
    "Not all properties of the object are always used. Which properties are unused depends on the network type specified. For classification there is no fusion or language part, therefore in this example all parameters associated with fusion or language modeling are unused.\n",
    ":::"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lhackel/Documents/development/ConfigVLM/.venv/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VLMConfiguration(timm_model_name='resnet18',\n",
      "                 hf_model_name=None,\n",
      "                 image_size=120,\n",
      "                 channels=3,\n",
      "                 classes=10,\n",
      "                 class_names=None,\n",
      "                 network_type=<VLMType.VISION_CLASSIFICATION: 0>,\n",
      "                 visual_features_out=512,\n",
      "                 fusion_in=512,\n",
      "                 fusion_hidden=256,\n",
      "                 v_dropout_rate=0.25,\n",
      "                 t_dropout_rate=0.25,\n",
      "                 fusion_dropout_rate=0.25,\n",
      "                 fusion_method=<built-in method mul of type object at 0x7f06fbcdd460>,\n",
      "                 fusion_activation=Tanh(),\n",
      "                 drop_rate=0.2,\n",
      "                 use_pooler_output=True,\n",
      "                 max_sequence_length=32,\n",
      "                 load_timm_if_available=False,\n",
      "                 load_hf_if_available=True)\n"
     ]
    }
   ],
   "source": [
    "# output_stderr = remove\n",
    "from configilm.ConfigILM import ILMConfiguration, ILMType\n",
    "from pprint import pprint\n",
    "model_config = ILMConfiguration(\n",
    "    timm_model_name=\"resnet18\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "All parameters as well as their respective default values can be seen below."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter name            | Type                                                         | Default value\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "timm_model_name           | <class 'str'>                                                |               <REQUIRED PARAM>\n",
      "hf_model_name             | typing.Optional[str]                                         |                           None\n",
      "image_size                | <class 'int'>                                                |                            120\n",
      "channels                  | <class 'int'>                                                |                              3\n",
      "classes                   | <class 'int'>                                                |                             10\n",
      "class_names               | typing.Optional[typing.Sequence[str]]                        |                           None\n",
      "network_type              | <enum 'VLMType'>                                             |  VLMType.VISION_CLASSIFICATION\n",
      "visual_features_out       | <class 'int'>                                                |                            512\n",
      "fusion_in                 | <class 'int'>                                                |                            512\n",
      "fusion_hidden             | <class 'int'>                                                |                            256\n",
      "v_dropout_rate            | <class 'float'>                                              |                           0.25\n",
      "t_dropout_rate            | <class 'float'>                                              |                           0.25\n",
      "fusion_dropout_rate       | <class 'float'>                                              |                           0.25\n",
      "fusion_method             | typing.Callable[[torch.Tensor, torch.Tensor], torch.Tensor]  |                      torch.mul\n",
      "fusion_activation         | typing.Callable[[torch.Tensor], torch.Tensor]                |                         Tanh()\n",
      "drop_rate                 | typing.Optional[float]                                       |                            0.2\n",
      "use_pooler_output         | <class 'bool'>                                               |                           True\n",
      "max_sequence_length       | <class 'int'>                                                |                             32\n",
      "load_timm_if_available    | <class 'bool'>                                               |                          False\n",
      "load_hf_if_available      | <class 'bool'>                                               |                           True\n"
     ]
    }
   ],
   "source": [
    "# remove-input\n",
    "type_len = 60\n",
    "print(f'{\"Parameter name\":<25} | {\"Type\":<60} | Default value')\n",
    "print(\"-\"*(25+3+60+3+30))\n",
    "conf = ILMConfiguration(timm_model_name=\"<REQUIRED PARAM>\").__dict__\n",
    "conf[\"fusion_method\"] = \"torch.mul\"\n",
    "for n, t in ILMConfiguration.__init__.__annotations__.items():\n",
    "    if n in conf.keys():\n",
    "        print(f\"{n:<25} | {str(t):<60} | {str(conf[n]):>30}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "This class is used to ultimately create the model, but also collects all other information such as the image size in an object. This facilitates the organization in the code and is to prevent that there are many global variables.\n",
    "Currently, the configuration supports the following network types:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# remove-input\n",
    "from pprint import pprint\n",
    "pprint([p.name for p in ILMType])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
